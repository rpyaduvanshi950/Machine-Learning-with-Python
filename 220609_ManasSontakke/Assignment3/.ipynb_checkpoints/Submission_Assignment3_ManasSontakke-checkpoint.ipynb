{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b89366-7db7-4c58-a421-eeb952d48e1b",
   "metadata": {},
   "source": [
    "The dataset is related to the red variant of \"Vinho Verde\" wine. It contains 1599 data points where features are the physicochemical properties and the target value is quality which is an integer score ranging from 0-10. Your task is to classify if the wine provided is good based on its physicochemical properties.\n",
    "\n",
    "(i) Create a new column on the dataset with binary values (i.e, 0 or 1) telling whether the wine is of good quality or not. You can categorise wines with quality>=7 to be of good quality. Drop the original ‘quality’ column.\n",
    "\n",
    "(ii) Perform the data pre-processing steps that you feel are important for the given dataset.\n",
    "\n",
    "(iii) Apply following classification algorithms on the given dataset (you are allowed to use scikit-learn library until not specified ‘from scratch’):\n",
    "\n",
    " Logistic Regression\n",
    " K-Nearest Neighbors\n",
    " Decision Trees Classifier\n",
    " Random Forest Classifier\n",
    " Logistic Regression from Scratch \n",
    "\n",
    "(iv) Evaluate all your models based on the accuracy score and f1 score obtained on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08b22ca5-c513-4dc1-9745-0dc5c29e19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('winequality-red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09025ea3-dea3-4327-9a2a-a80a2c36c16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['good_quality'] = (df['quality'] >= 7).astype(int)\n",
    "df = df.drop('quality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2053e878-226b-446a-9733-ea7fe79b4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df.drop('good_quality', axis=1)), columns=df.columns[:-1])\n",
    "df_scaled['good_quality'] = df['good_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b874a7da-4145-4a24-b1a5-3d91eae89f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('good_quality', axis=1)\n",
    "y = df_scaled['good_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b438d18b-5bae-4516-be92-b5baf25b239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db9da7f2-9e3c-434a-8497-9261f3eb3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86c1cea6-aefd-437b-875a-86c696a7482f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k value: 15\n",
      "Highest accuracy: 0.89375\n"
     ]
    }
   ],
   "source": [
    "# Finding Best value of K\n",
    "best_k = 0\n",
    "highest_accuracy = 0\n",
    "\n",
    "for k in range(1, 21):  # Testing k from 1 to 20\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    accuracy = knn.score(X_test, y_test)\n",
    "    if accuracy > highest_accuracy:\n",
    "        highest_accuracy = accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k value: {best_k}\")\n",
    "print(f\"Highest accuracy: {highest_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c89949b-b907-4587-9795-4d1642a45886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "log_reg_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=4)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Decision Trees\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "decision_tree_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "random_forest_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67cf090a-6c69-4bdb-b6e5-2b81c67a411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression from Scratch\n",
    "class LogisticRegressionScratch:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        m = len(y)\n",
    "        for _ in range(self.n_iterations):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h - y)) / m\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.round(self.sigmoid(np.dot(X, self.theta)))\n",
    "\n",
    "# Instantiate and train Logistic Regression from Scratch\n",
    "log_reg_scratch = LogisticRegressionScratch()\n",
    "log_reg_scratch.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "predictions_scratch = log_reg_scratch.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e405b80-602b-4036-9f13-693995d9d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy Score: 0.8656\n",
      "F1 Score: 0.8442\n",
      "-------------------------------------\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy Score: 0.8812\n",
      "F1 Score: 0.8590\n",
      "-------------------------------------\n",
      "Model: Decision Trees\n",
      "Accuracy Score: 0.8812\n",
      "F1 Score: 0.8790\n",
      "-------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy Score: 0.9094\n",
      "F1 Score: 0.9020\n",
      "-------------------------------------\n",
      "Model: Logistic Regression from Scratch\n",
      "Accuracy Score: 0.6750\n",
      "F1 Score: 0.7222\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = [\"Logistic Regression\", \"K-Nearest Neighbors\", \"Decision Trees\", \"Random Forest\", \"Logistic Regression from Scratch\"]\n",
    "predictions = [log_reg_pred, knn_pred, decision_tree_pred, random_forest_pred, predictions_scratch]\n",
    "\n",
    "for model, pred in zip(models, predictions):\n",
    "    acc_score = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Accuracy Score: {acc_score:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
